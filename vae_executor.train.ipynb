{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating valid_files\n",
      "done valid_files\n",
      "dataset done\n",
      "dataloader done\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"/home/luke/VIU/09MIAR/src\")\n",
    "\n",
    "from vae.datasets.audio_dataset import AudioDataset\n",
    "from vae.datasets.mp3_validator import MP3ValidatorDataset\n",
    "from vae.datasources.fma_datasource import FMADatasource\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('./VIU/09MIAR/src/vae/.env')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "datasets_path = '/home/luke/VIU/09MIAR/datasets'\n",
    "valid_files_csv_path = '/home/luke/valid_files.csv'\n",
    "\n",
    "def get_dataloader(datasets_path, valid_files_csv_path, num_mels):\n",
    "    fma_dataset = FMADatasource(datasets_path)\n",
    "\n",
    "    file_paths = fma_dataset.get_file_paths()\n",
    "    labels = fma_dataset.get_labels()\n",
    "    mp3Validator = MP3ValidatorDataset(file_paths,labels,valid_files_csv_path,num_mels,10,25,int(os.environ.get('SAMPLE_RATE')))\n",
    "     \n",
    "    num_tracks_per_genre, dict_dataset = fma_dataset.balanced(mp3Validator.getValidFiles() ,int(os.environ.get('LIMIT_FILES'))) # TODO: REMOVE -> limited to 500\n",
    "\n",
    "    file_paths = list(dict_dataset.keys())\n",
    "    labels = [dict_dataset[fp]['label'] for fp in file_paths]\n",
    "\n",
    "    dataset = AudioDataset(file_paths, labels)\n",
    "    print('dataset done')\n",
    "    \n",
    "    # dataloader = DataLoader(dataset, int(os.environ.get('TRAIN_BATCH_SIZE')), shuffle=False, drop_last=True, pin_memory=False)\n",
    "    dataloader = DataLoader(dataset, int(os.environ.get('TRAIN_BATCH_SIZE')), shuffle=True, num_workers=30)\n",
    "    print('dataloader done')\n",
    "\n",
    "    return dataloader, dataset\n",
    "\n",
    "dataloader, dataset = get_dataloader(datasets_path, valid_files_csv_path, int(os.environ.get('NUM_MELS')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class VAEDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,\n",
    "                 dataset_cls=None,\n",
    "                 dataset_kwargs=None,\n",
    "                 train_dataset=None,\n",
    "                 val_dataset=None,\n",
    "                 val_split=0.2,\n",
    "                 batch_size=1,\n",
    "                 num_workers=0):\n",
    "        super().__init__()\n",
    "        self.dataset_cls = dataset_cls\n",
    "        self.dataset_kwargs = dataset_kwargs or {}\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        self.val_split = val_split\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if self.train_dataset is not None and self.val_dataset is not None:\n",
    "            return\n",
    "\n",
    "        if self.train_dataset is not None and self.val_dataset is None:\n",
    "            total_len = len(self.train_dataset)\n",
    "            train_len = int((1 - self.val_split) * total_len)\n",
    "            val_len = total_len - train_len\n",
    "            self.train_dataset, self.val_dataset = random_split(self.train_dataset, [train_len, val_len])\n",
    "            return\n",
    "\n",
    "        if self.dataset_cls is None:\n",
    "            raise ValueError(\"Debe proporcionar 'dataset_cls' si no pasa ningún dataset ya instanciado.\")\n",
    "\n",
    "        full_dataset = self.dataset_cls(**self.dataset_kwargs)\n",
    "        train_size = int((1 - self.val_split) * len(full_dataset))\n",
    "        val_size = len(full_dataset) - train_size\n",
    "        self.train_dataset, self.val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          shuffle=False,\n",
    "                          num_workers=self.num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPEC_TIME_STEPS 501\n",
      "GENRE_EMBEDDING_DIM 8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv('./VIU/09MIAR/src/vae/.env')\n",
    "SAMPLE_RATE = int(os.environ[\"SAMPLE_RATE\"])\n",
    "N_FFT = int(os.environ[\"N_FFT\"])\n",
    "HOP_LENGTH = int(os.environ[\"HOP_LENGTH\"])\n",
    "NUM_MELS = int(os.environ[\"NUM_MELS\"])\n",
    "SEGMENT_DURATION = int(os.environ[\"SEGMENT_DURATION\"])\n",
    "LATENT_DIM = int(os.environ[\"LATENT_DIM\"])\n",
    "NUM_GENRES = int(os.environ[\"NUM_GENRES\"])\n",
    "\n",
    "\n",
    "SPEC_TIME_STEPS = int((SAMPLE_RATE * SEGMENT_DURATION) / HOP_LENGTH)\n",
    "print(f\"SPEC_TIME_STEPS {SPEC_TIME_STEPS}\")\n",
    "\n",
    "\n",
    "def next_power_of_two(n):\n",
    "    return 2 ** math.ceil(math.log2(n))\n",
    "\n",
    "GENRE_EMBEDDING_DIM = next_power_of_two(NUM_GENRES)\n",
    "print(f\"GENRE_EMBEDDING_DIM {GENRE_EMBEDDING_DIM}\")\n",
    "\n",
    "class VAE_Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.genre_embedding = nn.Embedding(NUM_GENRES, GENRE_EMBEDDING_DIM)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1 + GENRE_EMBEDDING_DIM, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dummy_spec = torch.zeros(1, 1, NUM_MELS, SPEC_TIME_STEPS)\n",
    "            dummy_genre = torch.zeros(1, dtype=torch.long)\n",
    "            dummy_emb = self.genre_embedding(dummy_genre).view(1, GENRE_EMBEDDING_DIM, 1, 1).expand(-1, -1, NUM_MELS, SPEC_TIME_STEPS)\n",
    "            dummy_input = torch.cat([dummy_spec, dummy_emb], dim=1)\n",
    "\n",
    "            dummy = self.pool(F.relu(self.bn1(self.conv1(dummy_input))))\n",
    "            dummy = self.pool(F.relu(self.bn2(self.conv2(dummy))))\n",
    "            dummy = self.pool(F.relu(self.bn3(self.conv3(dummy))))\n",
    "\n",
    "            self.flattened_shape = dummy.shape[1:]\n",
    "            self.feature_dim = dummy.numel()\n",
    "\n",
    "        self.fc_mu = nn.Linear(self.feature_dim, LATENT_DIM)\n",
    "        self.fc_logvar = nn.Linear(self.feature_dim, LATENT_DIM)\n",
    "\n",
    "    def forward(self, x, genre):\n",
    "        x = x[..., :SPEC_TIME_STEPS]\n",
    "        genre_emb = self.genre_embedding(genre).view(genre.size(0), GENRE_EMBEDDING_DIM, 1, 1)\n",
    "        genre_emb = genre_emb.expand(-1, -1, x.size(2), x.size(3))\n",
    "        x = torch.cat([x, genre_emb], dim=1)\n",
    "\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "\n",
    "        logvar = torch.clamp(logvar, min=-10.0, max=10.0)\n",
    "        return mu, logvar\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class VAE_Decoder(nn.Module):\n",
    "    def __init__(self, feature_dim, flattened_shape):\n",
    "        super().__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        self.flattened_shape = flattened_shape\n",
    "\n",
    "        self.genre_embedding = nn.Embedding(NUM_GENRES, GENRE_EMBEDDING_DIM)\n",
    "        self.fc = nn.Linear(LATENT_DIM + GENRE_EMBEDDING_DIM, feature_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=128, num_layers=1, batch_first=True)\n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "        self.output_pad = nn.ConstantPad2d((0, 5), 0)\n",
    "\n",
    "    def forward(self, z, genre):\n",
    "        genre_emb = self.genre_embedding(genre)\n",
    "        z = torch.cat([z, genre_emb], dim=1)\n",
    "\n",
    "        x = self.fc(z)\n",
    "        x = x.view(z.size(0), *self.flattened_shape)\n",
    "\n",
    "\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        B, H, C, W = x.shape\n",
    "        x = x.reshape(B * H, C, W).permute(0, 2, 1)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x.permute(0, 2, 1).reshape(B, H, C, W)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "\n",
    "        x = F.relu(self.deconv1(x))\n",
    "        x = F.relu(self.deconv2(x))\n",
    "        \n",
    "        x = self.deconv3(x)\n",
    "        x = self.output_pad(x)\n",
    "        \n",
    "        if not self.training:\n",
    "            import matplotlib.pyplot as plt\n",
    "\n",
    "            flat = x.detach().cpu().flatten()\n",
    "            x_min = flat.min().item()\n",
    "            x_max = flat.max().item()\n",
    "            x_mean = flat.mean().item()\n",
    "            x_std = flat.std().item()\n",
    "            sat_low = (flat <= -0.95).float().mean().item()\n",
    "            sat_high = (flat >= 0.95).float().mean().item()\n",
    "\n",
    "            print(f\"[DEBUG] Decoder output stats -> min: {x_min:.4f}, max: {x_max:.4f}, mean: {x_mean:.4f}, std: {x_std:.4f}\")\n",
    "            print(f\"[DEBUG] Saturación -> <= -0.95: {sat_low:.2%}, >= 0.95: {sat_high:.2%}\")\n",
    "\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            plt.hist(flat.numpy(), bins=50, color='purple', alpha=0.75)\n",
    "            plt.title(\"Histograma de valores del decoder\")\n",
    "            plt.xlabel(\"Valor\")\n",
    "            plt.ylabel(\"Frecuencia\")\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = VAE_Encoder()\n",
    "        self.decoder = VAE_Decoder(self.encoder.feature_dim, self.encoder.flattened_shape)\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def init_weights(self,m):\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Linear)):\n",
    "            nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        elif isinstance(m, nn.Embedding):\n",
    "            nn.init.uniform_(m.weight, -0.1, 0.1)\n",
    "        elif isinstance(m, nn.LSTM):\n",
    "            for name, param in m.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    nn.init.xavier_uniform_(param)\n",
    "                elif 'bias' in name:\n",
    "                    nn.init.zeros_(param)\n",
    "\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x, genre):\n",
    "        # print(f\"[ENCODER IN] x mean: {x.mean().item():.4f}, std: {x.std().item():.4f}\")\n",
    "        mu, logvar = self.encoder(x, genre)\n",
    "        # print(f\"[LATENT] mu mean: {mu.mean().item():.4f}, std: {mu.std().item():.4f}\")\n",
    "        # print(f\"[LATENT] logvar mean: {logvar.mean().item():.4f}, std: {logvar.std().item():.4f}\")\n",
    "\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_hat = self.decoder(z, genre)\n",
    "        if not torch.isfinite(x_hat).all():\n",
    "            print(\"[ERROR] x_hat contiene NaNs\")\n",
    "\n",
    "        # print(f\"[DECODER OUT] x_recon mean: {x_hat.mean().item():.4f}, std: {x_hat.std().item():.4f}\")\n",
    "\n",
    "\n",
    "        if not torch.isfinite(x).all():\n",
    "            print(\"[ERROR] Input contiene NaNs o infinitos\")\n",
    "        if not torch.isfinite(mu).all():\n",
    "            print(\"[ERROR] mu contiene NaNs\")\n",
    "        if not torch.isfinite(logvar).all():\n",
    "            print(\"[ERROR] logvar contiene NaNs\")\n",
    "\n",
    "        return x_hat, mu, logvar\n",
    "\n",
    "\n",
    "\n",
    "BETA_MAX = float(os.environ[\"BETA_MAX\"])\n",
    "BETA_WARMUP_EPOCHS = int(os.environ[\"BETA_WARMUP_EPOCHS\"])\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "class LitVAE(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = VAE()\n",
    "        self.register_buffer(\"x_sum\", torch.tensor(0.0))\n",
    "        self.register_buffer(\"x_squared_sum\", torch.tensor(0.0))\n",
    "        self.register_buffer(\"x_count\", torch.tensor(0))\n",
    "        self.std_x = 0\n",
    "        self.mean_x = 0\n",
    "        self.best_val_loss = float(\"inf\")\n",
    "\n",
    "        # Logs\n",
    "        self.train_step_metrics = []\n",
    "        self.val_step_metrics = []\n",
    "        self.train_epoch_metrics = []\n",
    "        self.val_epoch_metrics = []\n",
    "\n",
    "        os.makedirs(\"logs/csv\", exist_ok=True)\n",
    "        os.makedirs(\"logs/img\", exist_ok=True)\n",
    "        os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "    def forward(self, x, genre):\n",
    "        x = x[..., :SPEC_TIME_STEPS]\n",
    "        x_hat, mu, logvar = self.model(x, genre)\n",
    "        x_hat = x_hat[..., :SPEC_TIME_STEPS]\n",
    "        if x_hat.shape[-1] != x.shape[-1]:\n",
    "            min_width = min(x_hat.shape[-1], x.shape[-1])\n",
    "            x = x[..., :min_width]\n",
    "            x_hat = x_hat[..., :min_width]\n",
    "        return x_hat, x, mu, logvar\n",
    "\n",
    "    def compute_loss(self, x_hat, x, mu, logvar):\n",
    "        warmup = max(BETA_WARMUP_EPOCHS, 1)\n",
    "        step = self.current_epoch / warmup\n",
    "        beta = float(BETA_MAX / (1 + math.exp(-10 * (step - 0.5))))\n",
    "        beta = min(beta, BETA_MAX)\n",
    "\n",
    "        recon_loss = F.mse_loss(x_hat, x, reduction='mean')\n",
    "        kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.size(0)\n",
    "        loss = recon_loss + beta * kl_div\n",
    "        return loss, recon_loss, kl_div, beta\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, genre = batch\n",
    "        x_hat, x, mu, logvar = self(x, genre)\n",
    "\n",
    "        self.x_sum += x.sum()\n",
    "        self.x_squared_sum += (x ** 2).sum()\n",
    "        self.x_count += x.numel()\n",
    "\n",
    "        loss, recon_loss, kl_div, beta = self.compute_loss(x_hat, x, mu, logvar)\n",
    "\n",
    "        self.log(\"loss\", loss, prog_bar=True)\n",
    "        self.log(\"recon_loss\", recon_loss, prog_bar=True)\n",
    "        self.log(\"kl_div\", kl_div, prog_bar=True)\n",
    "        self.log(\"beta\", beta, prog_bar=True)\n",
    "\n",
    "        self.train_step_metrics.append({\n",
    "            \"epoch\": self.current_epoch,\n",
    "            \"batch\": batch_idx,\n",
    "            \"loss\": loss.item(),\n",
    "            \"recon_loss\": recon_loss.item(),\n",
    "            \"kl_div\": kl_div.item(),\n",
    "            \"beta\": beta\n",
    "        })\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, genre = batch\n",
    "        x_hat, x, mu, logvar = self(x, genre)\n",
    "        loss, recon_loss, kl_div, beta = self.compute_loss(x_hat, x, mu, logvar)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_recon_loss\", recon_loss, prog_bar=True)\n",
    "        self.log(\"val_kl_div\", kl_div, prog_bar=True)\n",
    "\n",
    "        self.val_step_metrics.append({\n",
    "            \"epoch\": self.current_epoch,\n",
    "            \"batch\": batch_idx,\n",
    "            \"val_loss\": loss.item(),\n",
    "            \"val_recon_loss\": recon_loss.item(),\n",
    "            \"val_kl_div\": kl_div.item(),\n",
    "            \"beta\": beta\n",
    "        })\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        if self.x_count > 0:\n",
    "            mean_x = self.x_sum / self.x_count\n",
    "            std_x = torch.sqrt(self.x_squared_sum / self.x_count - mean_x ** 2)\n",
    "            self.mean_x = mean_x.item()\n",
    "            self.std_x = std_x.item()\n",
    "            self.log(\"x_mean_epoch\", mean_x, prog_bar=True)\n",
    "            self.log(\"x_std_epoch\", std_x, prog_bar=True)\n",
    "            print(f\"[INFO] Época {self.current_epoch} completada — mean_x={self.mean_x:.4f}, std_x={self.std_x:.4f}\")\n",
    "        self.x_sum.zero_()\n",
    "        self.x_squared_sum.zero_()\n",
    "        self.x_count.zero_()\n",
    "\n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "        import torch\n",
    "\n",
    "        if self.train_step_metrics:\n",
    "            df_train = pd.DataFrame(self.train_step_metrics)\n",
    "            df_train.to_csv(\"logs/csv/metrics_train_step.csv\", mode='a', header=not os.path.exists(\"logs/csv/metrics_train_step.csv\"), index=False)\n",
    "            self.train_step_metrics.clear()\n",
    "\n",
    "        if self.val_step_metrics:\n",
    "            df_val = pd.DataFrame(self.val_step_metrics)\n",
    "            df_val.to_csv(\"logs/csv/metrics_val_step.csv\", mode='a', header=not os.path.exists(\"logs/csv/metrics_val_step.csv\"), index=False)\n",
    "            self.val_step_metrics.clear()\n",
    "\n",
    "        epoch_metrics = {\n",
    "            \"epoch\": self.current_epoch,\n",
    "            \"x_mean\": self.mean_x,\n",
    "            \"x_std\": self.std_x\n",
    "        }\n",
    "        self.train_epoch_metrics.append(epoch_metrics)\n",
    "        df_epoch = pd.DataFrame(self.train_epoch_metrics)\n",
    "        df_epoch.to_csv(\"logs/csv/metrics_train_epoch.csv\", index=False)\n",
    "\n",
    "        if self.val_epoch_metrics:\n",
    "            df_val_epoch = pd.DataFrame(self.val_epoch_metrics)\n",
    "            df_val_epoch.to_csv(\"logs/csv/metrics_val_epoch.csv\", index=False)\n",
    "\n",
    "        if len(df_epoch) > 1:\n",
    "            plt.figure()\n",
    "            plt.plot(df_epoch[\"epoch\"], df_epoch[\"x_mean\"], label=\"x_mean\")\n",
    "            plt.plot(df_epoch[\"epoch\"], df_epoch[\"x_std\"], label=\"x_std\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Valor\")\n",
    "            plt.legend()\n",
    "            plt.title(\"Media y desviación estándar de x\")\n",
    "            plt.savefig(f\"logs/img/stats_epoch_{self.current_epoch}.jpg\")\n",
    "            plt.close()\n",
    "\n",
    "        torch.save(self.state_dict(), f'''checkpoints/vae_last_{self.current_epoch}.pt''')\n",
    "\n",
    "        if self.val_epoch_metrics:\n",
    "            current_val_loss = self.val_epoch_metrics[-1][\"val_loss\"]\n",
    "            if current_val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = current_val_loss\n",
    "                torch.save(self.state_dict(), f\"checkpoints/vae_best.pt\")\n",
    "                print(f\"[INFO] Nuevo mejor modelo guardado (val_loss={current_val_loss:.4f})\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", patience=5, factor=0.5, verbose=True)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\",\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = LitVAE()\n",
    "\n",
    "# \n",
    "# trainer = pl.Trainer(max_epochs=int(os.environ.get('TRAIN_EPOCHS')))\n",
    "\n",
    "# \n",
    "# trainer.fit(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "2025-03-30 12:01:24.718474: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-30 12:01:24.736614: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-30 12:01:25.118702: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/luke/jupyter_env/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name  | Type | Params | Mode \n",
      "---------------------------------------\n",
      "0 | model | VAE  | 391 M  | train\n",
      "---------------------------------------\n",
      "391 M     Trainable params\n",
      "0         Non-trainable params\n",
      "391 M     Total params\n",
      "1,566.429 Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f3247da6344c2e94f5566e5cd0f327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Decoder output stats -> min: -2.5498, max: 2.0577, mean: -0.1738, std: 0.5428\n",
      "[DEBUG] Saturación -> <= -0.95: 7.86%, >= 0.95: 1.84%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Decoder output stats -> min: -2.4712, max: 2.5233, mean: -0.1719, std: 0.5497\n",
      "[DEBUG] Saturación -> <= -0.95: 8.06%, >= 0.95: 1.98%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c812289f4e154c759f4d6c2d72669b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/layer3.c:INT123_do_layer3():1844] error: dequantization failed!\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1844] error: dequantization failed!\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1844] error: dequantization failed!\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    595\u001b[0m     ckpt_path,\n\u001b[1;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m )\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1056\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py:150\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py:320\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m     batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:192\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:270\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:176\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/pytorch_lightning/core/module.py:1302\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;124;03mthe optimizer.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \n\u001b[1;32m   1301\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1302\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py:154\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py:239\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py:123\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/torch/optim/optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/torch/optim/adam.py:244\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    234\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    235\u001b[0m         group,\n\u001b[1;32m    236\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m         state_steps,\n\u001b[1;32m    242\u001b[0m     )\n\u001b[0;32m--> 244\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/torch/optim/adam.py:876\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    874\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 876\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/torch/optim/adam.py:706\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    705\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n\u001b[0;32m--> 706\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg_sq_sqrt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_addcdiv_(\n\u001b[1;32m    708\u001b[0m     device_params, device_exp_avgs, exp_avg_sq_sqrt, step_size  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    709\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[1;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     16\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAIN_EPOCHS\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[1;32m     17\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,        \u001b[38;5;66;03m# Usa GPU si está disponible\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     enable_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyter_env/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:65\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     64\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 65\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     68\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = LitVAE()\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "data_module = VAEDataModule(\n",
    "    train_dataset=dataset,\n",
    "    val_split=0.2,\n",
    "    batch_size=1,\n",
    "    num_workers=32\n",
    ")\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=int(os.environ.get('TRAIN_EPOCHS')),\n",
    "    accelerator=\"auto\",\n",
    "    log_every_n_steps=1,\n",
    "    enable_checkpointing=True,\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "trainer.fit(model, datamodule=data_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_audio_from_noise(model: LitVAE, genre_id: int, output_path: str = \"generated.wav\"):\n",
    "    DB_MIN = -80.0\n",
    "    DB_MAX = 0.0\n",
    "\n",
    "    device = model.device\n",
    "    model.eval()\n",
    "    vae = model.model\n",
    "\n",
    "    z = torch.randn(1, LATENT_DIM).to(device)\n",
    "    genre = torch.tensor([genre_id], dtype=torch.long).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        spec = vae.decoder(z, genre)\n",
    "\n",
    "    spec = spec.squeeze().cpu()\n",
    "\n",
    "    spec_min = spec.min().item()\n",
    "    spec_max = spec.max().item()\n",
    "    print(f\"[DEBUG] spec antes de denormalizar: min={spec_min:.4f}, max={spec_max:.4f}\")\n",
    "\n",
    "    if abs(spec_max - spec_min) < 1e-3:\n",
    "        print(\"[WARNING] El espectrograma generado tiene un rango demasiado pequeño\")\n",
    "\n",
    "    try:\n",
    "        mean_x = model.mean_x.item() if hasattr(model.mean_x, 'item') else float(model.mean_x)\n",
    "        std_x = model.std_x.item() if hasattr(model.std_x, 'item') else float(model.std_x)\n",
    "        print(f\"[INFO] Usando mean_x={mean_x}, std_x={std_x} para denormalización temporal\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Acceso a mean_x o std_x: {e}\")\n",
    "        mean_x, std_x = 0.0, 1.0\n",
    "\n",
    "    if std_x == 0:\n",
    "        print(\"[WARNING] std_x es 0, se omite denormalización\")\n",
    "    else:\n",
    "        spec = spec * std_x + mean_x\n",
    "\n",
    "    spec_db = spec * (DB_MAX - DB_MIN) + DB_MIN\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.imshow(spec_db.numpy(), aspect='auto', origin='lower', cmap='magma')\n",
    "    plt.title(f\"Espectrograma generado (género {genre_id})\")\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    inverse_mel = torchaudio.transforms.InverseMelScale(\n",
    "        n_stft=N_FFT // 2 + 1,\n",
    "        n_mels=NUM_MELS,\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "    )\n",
    "    griffin_lim = torchaudio.transforms.GriffinLim(\n",
    "        n_fft=N_FFT,\n",
    "        hop_length=HOP_LENGTH,\n",
    "        power=2.0\n",
    "    )\n",
    "\n",
    "    spec_amp = torch.pow(10.0, spec_db / 20.0)\n",
    "    spec_amp = spec_amp.unsqueeze(0)\n",
    "    linear_spec = inverse_mel(spec_amp)\n",
    "    waveform = griffin_lim(linear_spec)\n",
    "\n",
    "    torchaudio.save(output_path, waveform, SAMPLE_RATE)\n",
    "    print(f\"Audio generado guardado en: {output_path}\")\n",
    "\n",
    "    return waveform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_audio_from_noise(model, genre_id=0, output_path=\"sample_genre0.wav\")\n",
    "generate_audio_from_noise(model, genre_id=1, output_path=\"sample_genre1.wav\")\n",
    "generate_audio_from_noise(model, genre_id=2, output_path=\"sample_genre2.wav\")\n",
    "generate_audio_from_noise(model, genre_id=3, output_path=\"sample_genre3.wav\")\n",
    "generate_audio_from_noise(model, genre_id=4, output_path=\"sample_genre4.wav\")\n",
    "generate_audio_from_noise(model, genre_id=7, output_path=\"sample_genre7.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))\n",
    "\n",
    "\n",
    "x, y = batch\n",
    "\n",
    "print(\"Shape del batch completo (x):\", x.shape)\n",
    "print(\"Shape del target (y):\", y.shape if y is not None else \"None\")\n",
    "\n",
    "\n",
    "print(\"\\nEjemplo individual:\")\n",
    "ejemplo = x[0]\n",
    "print(\"Shape del ejemplo:\", ejemplo.shape)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if ejemplo.ndim == 3:\n",
    "\n",
    "    plt.imshow(ejemplo.squeeze().cpu(), aspect='auto', origin='lower')\n",
    "    plt.title(\"Espectrograma del primer segmento\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "elif ejemplo.ndim == 4:\n",
    "\n",
    "    print(\"Número de segmentos:\", ejemplo.shape[0])\n",
    "    fig, axs = plt.subplots(1, ejemplo.shape[0], figsize=(15, 3))\n",
    "    for i in range(ejemplo.shape[0]):\n",
    "        axs[i].imshow(ejemplo[i].squeeze().cpu(), aspect='auto', origin='lower')\n",
    "        axs[i].set_title(f\"Segmento {i+1}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Formato no esperado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyter_env)",
   "language": "python",
   "name": "jupyter_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
